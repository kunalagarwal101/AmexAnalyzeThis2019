# -*- coding: utf-8 -*-
"""main.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UhQWkgIGm2thEQVvqRjGvk-_dqY62ao3

# Data Preparation

## Data Importing

imported the libraries to be used.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

home_data = pd.read_csv('development_dataset.csv', index_col=0)

home_data.head()

home_data['VAR10'].value_counts(sort=True)

leader_data = pd.read_csv('leaderboard_dataset.csv', index_col=0)

leader_data.head()

"""# Data Splitting"""

home_data.shape

leader_data.shape

from sklearn.model_selection import train_test_split

train_data, val_data = train_test_split(home_data, test_size = 0.3, random_state = 2)

train_data.shape

val_data.shape

y_train = train_data['VAR21']
y_val = val_data['VAR21']
X_train = train_data.drop(['VAR21'], axis = 1)
X_val = val_data.drop(['VAR21'], axis = 1)

X_train.shape, y_train.shape

X_val.shape, y_val.shape

X_train.head()

y_train.head()

"""# Exploratory Data Analysis

## Univariate Analysis
"""

X_train.head()

X_train.dtypes

X_train['VAR14'].value_counts()

"""# Step1: Change VAR14 to numeric and introduce NaNs"""

X_train['VAR14'] = X_train['VAR14'].replace('.', np.nan)
X_train['VAR14'] = X_train['VAR14'].apply(pd.to_numeric)

X_val['VAR14'] = X_val['VAR14'].replace('.', np.nan)
X_val['VAR14'] = X_val['VAR14'].apply(pd.to_numeric)

leader_data['VAR14'] = leader_data['VAR14'].replace('.', np.nan)
leader_data['VAR14'] = leader_data['VAR14'].apply(pd.to_numeric)

X_train['VAR14'].value_counts()

X_train.dtypes

"""# Plotting Distributions"""

fig = plt.figure(figsize=(15,15))
for i, col in enumerate(X_train.columns):  
    ax = fig.add_subplot(7, 3, i+1)
    sns.distplot(X_train[col].dropna())

"""**ALMOST ALL VARIABLES ARE HIGHLY RIGHT SKEW**"""

X_train.describe()

plt.figure(figsize=(30,30))
sns.pairplot(X_train.dropna())

"""## Observations
- Var7, Var16 very low variance
- Var3 and Var8 also seem to have a low variance problem somewhat
- Var13, Var15 some linear relationship
- Var10 seems to have similar relationship with other variables symmetric about 50%

## Observing correlations
"""

X_train.corr()

sns.heatmap(X_train.corr())

"""**Some high correlations**:
- Var7 & Var16: 0.92
- Var7 & Var8: 0.7
- Var13 & Var15: 0.88
- Var11 & Var15: 0.63
- Var2 & Var4: -0.5

**On combing paiplots and correlation understanding**:
- Var 7 and Var16 can be explained on the basis of Var8
- Var7 and Var16 anyway have a very less variance
- Var13 and Var15 also seem to be correlated to each other (their distribution to others are also similar)
- On business understanding it is understood that Var13 (preferred_spend_line) and Var15 (prefered_balance_line) are also similar meanings

## Visualizing paiplots with target variable too
"""

home_data.boxplot(by='VAR21', figsize=(40,40))

"""# Some Random Testing"""

test_target = home_data['VAR21'].replace({'Low':1, 'Medium':2, 'High':3})

test_df = pd.DataFrame()
test_df['VAR15'] = home_data['VAR15']
test_df['VAR21'] = test_target

sns.pairplot(test_df.dropna())

test_df['cred_line_6m'] = home_data['VAR8']/home_data['VAR5']

sns.pairplot(test_df[['cred_line_6m', 'VAR21']].dropna())

test_df[['cred_line_6m', 'VAR21']].boxplot(by='VAR21', figsize=(20,20))

test_df.groupby(['VAR21']).mean()

home_data.groupby(['VAR21']).median()

home_data.groupby(['VAR21']).mean()

home_data[['VAR15', 'VAR21']].boxplot(by='VAR21', figsize=(40,40))

"""**Not much information gained**"""

home_data['VAR21'].value_counts()

"""**A little imbalanced data**

# Dealing with Missing Values
"""

# Missing values treatment with Iterative Imputer
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer

imp = IterativeImputer(max_iter=150, random_state=0)
imp.fit(X_train.values)
imputed_array = imp.transform(X_train.values)

X_train = pd.DataFrame(data=imputed_array, columns = X_train.columns, index = X_train.index)

X_train.shape

X_val.shape

leader_data.shape

X_train.head()

X_val_data = imp.transform(X_val)

X_leader_data = imp.transform(leader_data)

X_val = pd.DataFrame(data=X_val_data, index=X_val.index, columns=X_val.columns)

leader_data = pd.DataFrame(data=X_leader_data, index = leader_data.index, columns=leader_data.columns)

X_val.head()

leader_data.head()

"""## Plots after Imputation"""

fig = plt.figure(figsize=(15,15))
for i, col in enumerate(X_train.columns):
    ax = fig.add_subplot(7, 3, i+1)
    sns.distplot(X_train[col].dropna())

"""# Transformation of Data"""

from sklearn import preprocessing
pt = preprocessing.PowerTransformer(method='yeo-johnson', standardize=False)

pt.fit(X_train)

pt.transform(X_train)

X_train_val = pt.transform(X_train)
X_val_values = pt.transform(X_val)
X_leader_val = pt.transform(leader_data)

X_train = pd.DataFrame(data=X_train_val, index=X_train.index, columns=X_train.columns)
X_val = pd.DataFrame(data=X_val_values, index=X_val.index, columns=X_val.columns)
leader_data = pd.DataFrame(data=X_leader_val, index=leader_data.index, columns=leader_data.columns)

X_train.head()

X_val.head()

leader_data.head()

"""# Plots after Power Trasform"""

fig = plt.figure(figsize=(15,15))
for i, col in enumerate(X_train.columns):
    ax = fig.add_subplot(7, 3, i+1)
    sns.distplot(X_train[col].dropna())

"""# Feature Scaling"""

from sklearn.preprocessing import RobustScaler
scaler = RobustScaler()

scaler.fit(X_train)

X_train_val = scaler.transform(X_train)
X_val_values = scaler.transform(X_val)
X_leader_val = scaler.transform(leader_data)

X_train = pd.DataFrame(data=X_train_val, index=X_train.index, columns=X_train.columns)
X_val = pd.DataFrame(data=X_val_values, index=X_val.index, columns=X_val.columns)
leader_data = pd.DataFrame(data=X_leader_val, index=leader_data.index, columns=leader_data.columns)

"""# Plotting After Scaling"""

fig = plt.figure(figsize=(15,15))
for i, col in enumerate(X_train.columns):
    ax = fig.add_subplot(7, 3, i+1)
    sns.distplot(X_train[col].dropna())

X_train.shape

X_val.shape

leader_data.shape

fig = plt.figure(figsize=(15,15))
for i, col in enumerate(X_val.columns):
    ax = fig.add_subplot(7, 3, i+1)
    sns.distplot(X_val[col].dropna())

fig = plt.figure(figsize=(15,15))
for i, col in enumerate(leader_data.columns):
    ax = fig.add_subplot(7, 3, i+1)
    sns.distplot(leader_data[col].dropna())

X_train.shape

X_val.shape

leader_data.shape

y_train.shape

y_val.shape

leader_data.head()

X_train.head()

"""# Changing target variables"""

y_train = y_train.replace({'Low':0, 'Medium':1, 'High':2})
y_val = y_val.replace({'Low':0, 'Medium':1, 'High':2})

"""# Feature Engineering"""

# Trying Feature Engineering

X_train_new = X_train.drop(['VAR10', 'VAR16', 'VAR14', 'VAR18', 'VAR19', 'VAR9', 'VAR17'], axis =1)
X_train_new['remit_by_balance_int'] = X_train['VAR7']/(X_train['VAR8'])
X_train_new['utilization_ext'] = X_train['VAR11']/(X_train['VAR13'] + X_train['VAR15'])

X_val_new = X_val.drop(['VAR10', 'VAR16', 'VAR14', 'VAR18', 'VAR19', 'VAR9', 'VAR17'], axis =1)
X_val_new['remit_by_balance_int'] = X_val['VAR7']/(X_val['VAR8'])
X_val_new['utilization_ext'] = X_val['VAR11']/(X_val['VAR13'] + X_val['VAR15'])

X_leader_new = leader_data.drop(['VAR10', 'VAR16', 'VAR14', 'VAR18', 'VAR19', 'VAR9', 'VAR17'], axis =1)
X_leader_new['remit_by_balance_int'] = leader_data['VAR7']/(leader_data['VAR8'])
X_leader_new['utilization_ext'] = leader_data['VAR11']/(leader_data['VAR13'] + leader_data['VAR15'])

X_train_new.head()

"""# Data Preparation ends here

# Creating some miscellaneous functions
"""

def create_output(clf, num_attempt):
    y_leader = clf.predict(X_leader_new.values)
    final_data = pd.DataFrame(index = X_leader_new.index)
    final_data[0] = y_leader
    final_data[0] = final_data[0].replace({0:'Low', 1:'Medium', 2:'High'})
    final_data.to_csv('Intelliqo_IITGuwahati_'+str(num_attempt)+'.csv', header = None)

def my_scorer(y, y_pred):
    
    score = 1000*(y_pred==y).sum() - 50*((y_pred==0) & (y==1)).sum() - 50*((y_pred==1) & (y==2)).sum() - 100*((y_pred==1) & (y==0)).sum() - 100*((y_pred==0) & (y==2)).sum() - 200*((y_pred==2) & (y==0)).sum()
    
    return score

from sklearn.metrics import make_scorer
my_score = make_scorer(my_scorer, greater_is_better=True)

def print_results(clf, X_train, y_train, X_val, y_val):
    print('Training acc: ', clf.score(X_train.values, y_train.values))
    print('Validation acc: ', clf.score(X_val.values, y_val.values))
    print('Training score: ', my_score(clf, X_train.values, y_train.values))
    print('Validation score: ', my_score(clf, X_val.values, y_val.values))
    print('Confusion Matrix for Training:')
    print(confusion_matrix(y_train.values, clf.predict(X_train.values)))
    print('Confusion Matrix for Validation:')
    print(confusion_matrix(y_val.values, clf.predict(X_val.values)))

def print_results2(clf, X_train, y_train, X_val, y_val):
    print('Training acc: ', clf.score(X_train, y_train))
    print('Validation acc: ', clf.score(X_val.values, y_val.values))
    print('Training score: ', my_score(clf, X_train, y_train))
    print('Validation score: ', my_score(clf, X_val.values, y_val.values))
    print('Confusion Matrix for Training:')
    print(confusion_matrix(y_train, clf.predict(X_train)))
    print('Confusion Matrix for Validation:')
    print(confusion_matrix(y_val.values, clf.predict(X_val.values)))



from sklearn.metrics import confusion_matrix

from sklearn.model_selection import GridSearchCV

"""# Importing Models"""

from sklearn.ensemble import GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.svm import SVC
from xgboost import XGBClassifier
from sklearn.ensemble import VotingClassifier

"""# Handling Imbalanced Dataset

## Method 1: Undersampling + Oversampling

### NOTE: These methods are only applied on Training dataset
"""

from sklearn.utils import resample

# Combing X and y into one
X = pd.concat([X_train_new, y_train], axis=1)

# Generating different samples
high_samples = X[X['VAR21']==2]
med_samples = X[X['VAR21']==1]
low_samples = X[X['VAR21']==0]

print(X['VAR21'].value_counts())

high_upsampled = resample(high_samples,
                          replace=True, # sample with replacement
                          n_samples=6000, # match number in majority class
                          random_state=2) # reproducible results

med_downsampled = resample(med_samples,
                          replace=False, # sample with replacement
                          n_samples=10000, # match number in majority class
                          random_state=2) # reproducible results

low_downsampled = resample(low_samples,
                          replace=False, # sample with replacement
                          n_samples=6000, # match number in majority class
                          random_state=2) # reproducible results 

print(len(med_downsampled))
print(len(high_upsampled))
print(len(low_downsampled))

X_sampled = pd.concat([med_downsampled, high_upsampled, low_downsampled])
y_sampled = X_sampled['VAR21']
X_sampled.drop(['VAR21'], axis=1, inplace=True)

print(X_sampled.shape)

print(y_sampled.shape)

"""## Step2: SMOTE"""

from imblearn.over_sampling import SMOTE
sm = SMOTE(random_state = 2)

X_smote, y_smote = sm.fit_sample(X_train_new, y_train)

X_smote.shape

pd.Series(y_smote).value_counts()

"""# Now we have these datasets:
- **Training dataset**:
    - W/o feature engineering: X_train, y_train
    - With feature engineering: X_train_new, y_train
    - With sampling: X_sampled, y_sampled
    - With SMOTE: X_smote, y_smote
- **Validation dataset:**
    - W/o feature engineering: X_val, y_val
    - With feature engineering: X_val_new, y_val
- **Leaderboard Dataset:**
    - W/o feature engineering: leader_data
    - With feature engineering: X_leader_data

# Now the Meat of the Problem: Modelling

# Model1: XGBoost
"""

xgb = XGBClassifier(max_depth=2, learning_rate=0.06, n_estimators=2000, subsample=0.5, colsample_bytree=0.35, gamma=1, min_child_weight=12)

xgb.fit(X_train_new.values, y_train.values)

print_results(xgb, X_train_new, y_train, X_val_new, y_val)

create_output(xgb, 47)

"""# Model2: SVC"""

svc = SVC(C=0.3, class_weight='balanced', degree=6, probability=True)

svc.fit(X_train_new, y_train)

print_results(svc, X_train_new, y_train, X_val_new, y_val)

"""# Voting"""

eclf = VotingClassifier(estimators=[('xgb', xgb), ('svc', svc)], voting='hard')

eclf.fit(X_train_new.values, y_train.values)

print_results(eclf, X_train_new, y_train, X_val_new, y_val)

create_output(eclf, 44)

"""# LogisticRegression"""

from sklearn.linear_model import LogisticRegressionCV

lr = LogisticRegressionCV(cv=5, scoring=my_score, max_iter=400, n_jobs=-1, multi_class='multinomial')

lr.fit(X_train_new, y_train)

print_results(lr, X_train_new, y_train, X_val_new, y_val)

"""# GridSearch on XGB"""

from sklearn.model_selection import RandomizedSearchCV, GridSearchCV

params = {
        'learning_rate': [0.03, 0.06, 0.08],
        'min_child_weight': [1, 5, 10],
        'gamma': [1, 1.5, 2, 5],
        'subsample': [0,3, 0.6],
        'colsample_bytree': [0.6, 0.8],
        'max_depth': [2, 3]
        }

xgb = XGBClassifier(n_estimators=800,
                    silent=True, nthread=1)

random_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=3, scoring=my_score, n_jobs=-1, cv=5, verbose=3, random_state=2 )

random_search.fit(X_train_new.values, y_train.values)

print_results(random_search, X_train_new, y_train, X_val_new, y_val)



"""# Final Evaluation Dataset Submission"""

eval_data = pd.read_csv('Evaluation_dataset.csv', index_col=0)

eval_data.head()

eval_data['VAR14'] = eval_data['VAR14'].replace('.', np.nan)
eval_data['VAR14'] = eval_data['VAR14'].apply(pd.to_numeric)

X_eval_data = imp.transform(eval_data)
eval_data = pd.DataFrame(data=X_eval_data, index = eval_data.index, columns=eval_data.columns)

X_eval_val = pt.transform(eval_data)
eval_data = pd.DataFrame(data=X_eval_val, index=eval_data.index, columns=eval_data.columns)

X_eval_val = scaler.transform(eval_data)
eval_data = pd.DataFrame(data=X_eval_val, index=eval_data.index, columns=eval_data.columns)

X_eval_new = eval_data.drop(['VAR10', 'VAR16', 'VAR14', 'VAR18', 'VAR19', 'VAR9', 'VAR17'], axis =1)
X_eval_new['remit_by_balance_int'] = eval_data['VAR7']/(eval_data['VAR8'])
X_eval_new['utilization_ext'] = eval_data['VAR11']/(eval_data['VAR13'] + eval_data['VAR15'])

def create_output2(clf):
    y_eval = clf.predict(X_eval_new.values)
    final_data = pd.DataFrame(index = X_eval_new.index)
    final_data[0] = y_eval
    final_data[0] = final_data[0].replace({0:'Low', 1:'Medium', 2:'High'})
    final_data.to_csv('Intelliqo_IITGuwahati.csv', header = None)

def my_scorer(y, y_pred):
    
    score = 1000*(y_pred==y).sum() - 50*((y_pred==0) & (y==1)).sum() - 50*((y_pred==1) & (y==2)).sum() - 100*((y_pred==1) & (y==0)).sum() - 100*((y_pred==0) & (y==2)).sum() - 200*((y_pred==2) & (y==0)).sum()
    
    return score

from sklearn.metrics import make_scorer
my_score = make_scorer(my_scorer, greater_is_better=True)

def print_results(clf, X_train, y_train, X_val, y_val):
    print('Training acc: ', clf.score(X_train.values, y_train.values))
    print('Validation acc: ', clf.score(X_val.values, y_val.values))
    print('Training score: ', my_score(clf, X_train.values, y_train.values))
    print('Validation score: ', my_score(clf, X_val.values, y_val.values))
    print('Confusion Matrix for Training:')
    print(confusion_matrix(y_train.values, clf.predict(X_train.values)))
    print('Confusion Matrix for Validation:')
    print(confusion_matrix(y_val.values, clf.predict(X_val.values)))

def print_results2(clf, X_train, y_train, X_val, y_val):
    print('Training acc: ', clf.score(X_train, y_train))
    print('Validation acc: ', clf.score(X_val.values, y_val.values))
    print('Training score: ', my_score(clf, X_train, y_train))
    print('Validation score: ', my_score(clf, X_val.values, y_val.values))
    print('Confusion Matrix for Training:')
    print(confusion_matrix(y_train, clf.predict(X_train)))
    print('Confusion Matrix for Validation:')
    print(confusion_matrix(y_val.values, clf.predict(X_val.values)))

create_output2(xgb)

X_eval_new.head()

